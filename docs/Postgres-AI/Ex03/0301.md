---
title: '01. Exploring Cases RAG application'
layout: default
nav_order: 1
parent: 'Exercise 03: How RAG chatbot accuracy improves with different techniques'
---

## Task 01: Exploring Cases RAG application

We already created a sample Legal Cases RAG application so you can explore a RAG application. This application uses a **larger subset of legal cases data** than what you’ve explored in this lab, to provide more in-depth answers.

1. In a new browser tab, go to [https://abeomorogbe-graphra-ca.gentledune-632d42cd.eastus2.azurecontainerapps.io](https://abeomorogbe-graphra-ca.gentledune-632d42cd.eastus2.azurecontainerapps.io) to see our sample RAG application.

    ![RAG App screenshot](../media/azure-RAG-app-demo.png)

1. Select **Water leaking into the apartment** from the example queries.

    ![rqpeiuzq.jpg](../media/rqpeiuzq.jpg)

    ![y1r0drng.jpg](../media/y1r0drng.jpg)

    {: .note }
    > The RAG application uses the results from a vector search to answer your questions. 
    
1. Try any other query to test the limits of the application.

---

### Review accuracy of vector search queries

For the sample question, we’ve manually identified 10 legal cases that will produce the best answers. To explore the accuracy of vector search, follow these instructions:

1. Select the **Show graph** icon in the upper right of the prompt's response to see which cases were used to answer the question. 

    ![Graph screenshot](../media/RAG-app-demo-graph-icon.png)

1. On the **Citation Graph**, note that vector search only retrieved 40% of the most relevant cases. The orange indicates what was retrieved to answer the questions, and green indicates what should be retrieved for the sample question.

    ![Recall of Graph screenshot](../media/RAG-app-demo-recall-graph.png)

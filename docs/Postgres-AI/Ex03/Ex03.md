---
title: 'Exercise 03: How RAG chatbot accuracy improves with different techniques'
layout: default
nav_order: 4
has_children: true
---

# Exercise 03: How RAG chatbot accuracy improves with different techniques

Retrieval-Augmented Generation (RAG) can provide more accurate chatbot responses by combining vector searches, improved ranking, and knowledge graph techniques. For the City of Metropolis, this helps officials handle complex inquiries by linking relevant data with large language models.

## What is RAG
The Retrieval-Augmented Generation (RAG) system is a sophisticated architecture designed to enhance user interactions through a seamless integration of various technological components. At its core, RAG is composed of:

1. Raw data source is chunked for embedding.
2. Data is embedded with OpenAI embedding model and saved in Postgres.
3. User can send in query from the application.
4. Query is embedding with OpenAI embedding model and vectorized for search.
5. Vector search on Postgres performed using the [pgvector extension](https://github.com/pgvector/pgvector).
6. Retrieved context is stored to be used in the prompt to an LLM (GPT 4o).
7. The prompt and the retrieved context is fed into an LLM (GPT 4o) for improved chat results.
8. The generated output is fed to the chat application.
9. The user sees the chat response.
10. All responses can be tracked for future evaluation.

![Screenshot about RAG](./instructions282962/new-rag-diagram.png)